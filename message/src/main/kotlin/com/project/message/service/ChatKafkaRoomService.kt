
package com.project.message.service

import com.project.message.dto.ChatMessageDTO
import org.apache.kafka.clients.consumer.ConsumerConfig
import org.apache.kafka.clients.consumer.KafkaConsumer
import org.apache.kafka.common.TopicPartition
import org.apache.kafka.common.serialization.StringDeserializer
import org.springframework.beans.factory.annotation.Value
import org.springframework.kafka.annotation.KafkaListener
import org.springframework.kafka.core.KafkaTemplate
import org.springframework.kafka.support.serializer.JsonDeserializer
import org.springframework.stereotype.Service
import reactor.core.publisher.Flux
import reactor.core.publisher.Sinks
import java.time.Duration
import java.util.*

@Service
class ChatKafkaService(
    private val kafkaTemplate: KafkaTemplate<String, ChatMessageDTO>,
    @Value("\${spring.kafka.bootstrap-servers:localhost:9092}")
    private val bootstrapServers: String
) {
    /**
     * ğŸ”Š ê¸€ë¡œë²Œ ë¸Œë¡œë“œìºìŠ¤íŠ¸ Sink (ë°©ë³„ ë§µ ì œê±°)
     * - ì œí•œ ë²„í¼ë¡œ ë©”ëª¨ë¦¬ í­ì£¼ ë°©ì§€
     * - ëª¨ë“  ë°© ë©”ì‹œì§€ë¥¼ í•œ ê³³ìœ¼ë¡œ ëª¨ì•„ ìŠ¤íŠ¸ë¦¼ ì œê³µ, í´ë¼ì´ì–¸íŠ¸ëŠ” roomIdë¡œ í•„í„°
     */
    private val broadcastSink: Sinks.Many<ChatMessageDTO> = Sinks.many()
        .multicast()
        .onBackpressureBuffer(
            /* bufferSize */ 10_000,
            /* overflowStrategy */ false
        )

    private val broadcastFlux: Flux<ChatMessageDTO> = broadcastSink.asFlux()

    init {
        println("[ChatKafkaService] ğŸš€ ì´ˆê¸°í™”ë¨")
    }

    /**
     * íŠ¹ì • ì±„íŒ…ë°©ì˜ ë¼ì´ë¸Œ ë©”ì‹œì§€ ìŠ¤íŠ¸ë¦¼ ì œê³µ
     * - ê¸€ë¡œë²Œ ìŠ¤íŠ¸ë¦¼ì—ì„œ roomIdë¡œ í•„í„°
     */
    fun getRoomFlux(roomId: String): Flux<ChatMessageDTO> {
        println("[Kafka] ğŸ“¡ ë£¸ í”ŒëŸ­ìŠ¤ ì¡°íšŒ: room=$roomId")
        return broadcastFlux
            .filter { it.roomId == roomId }
            .doOnSubscribe { println("[Kafka] ğŸ‘¥ êµ¬ë… ì‹œì‘: room=$roomId") }
            .doFinally { signal -> println("[Kafka] ğŸ‘¥ êµ¬ë… ì¢…ë£Œ: room=$roomId, signal=$signal") }
    }

    /**
     * ì±„íŒ…ë°©ì— ë©”ì‹œì§€ ë°œí–‰ (Kafkaì— ë°œí–‰)
     * - ë‚®ì€ ë ˆì´í„´ì‹œë¥¼ ì›í•˜ë©´ ë¡œì»¬ ë¸Œë¡œë“œìºìŠ¤íŠ¸ì—ë„ í•¨ê»˜ ë°œí–‰
     */
    fun publishMessage(msg: ChatMessageDTO) {
        println("[Kafka] ğŸ“¤ ë©”ì‹œì§€ ë°œí–‰: room=${msg.roomId}, message=${msg.message}")

        // Kafka ë°œí–‰ (í‚¤ì— roomId ì„¤ì • â†’ íŒŒí‹°ì…˜ ë‹¨ìœ„ ìˆœì„œ ë³´ì¥)
        kafkaTemplate.send("chat-messages", msg.roomId, msg)
            .whenComplete { result, ex ->
                if (ex != null) {
                    println("[Kafka] âŒ Kafka ë°œí–‰ ì‹¤íŒ¨: ${ex.message}")
                } else {
                    println("[Kafka] âœ… Kafka ë°œí–‰ ì™„ë£Œ: partition=${result.recordMetadata.partition()}, offset=${result.recordMetadata.offset()}")
                }
            }

        // ì„ íƒ: ë¡œì»¬ ë¸Œë¡œë“œìºìŠ¤íŠ¸ë¡œ ì¦‰ì‹œ ì „ë‹¬(ì§€ì—° ìµœì†Œí™”)
        val emit = broadcastSink.tryEmitNext(msg)
        if (emit.isFailure) {
            println("[Kafka] âš ï¸ ë¡œì»¬ ë¸Œë¡œë“œìºìŠ¤íŠ¸ ì‹¤íŒ¨: room=${msg.roomId}, result=$emit")
        }
    }

    /**
     * Kafkaì—ì„œ ìµœê·¼ ë©”ì‹œì§€ ë¡œë“œ (ì •í™•í•œ ì¬ìƒ)
     * - ê° íŒŒí‹°ì…˜ì˜ endOffsetsì—ì„œ limitë§Œí¼ ë’¤ë¡œ ì´ë™í•˜ì—¬ ì½ê¸°
     * - roomId í‚¤ë¡œ í•„í„°ë§ í›„ ë§ˆì§€ë§‰ limitê°œ ë°˜í™˜
     */
    fun loadRecentMessages(roomId: String, limit: Int): List<ChatMessageDTO> {
        println("[Kafka] ğŸ“š ìµœê·¼ ë©”ì‹œì§€ ë¡œë“œ ì‹œì‘: room=$roomId, limit=$limit")

        return try {
            val props = Properties().apply {
                put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, bootstrapServers)
                put(ConsumerConfig.GROUP_ID_CONFIG, "history-reader-${System.currentTimeMillis()}")
                put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, StringDeserializer::class.java.name)
                put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, JsonDeserializer::class.java.name)
                put(JsonDeserializer.VALUE_DEFAULT_TYPE, ChatMessageDTO::class.java.name)
                put(JsonDeserializer.TRUSTED_PACKAGES, "*")
                put(ConsumerConfig.AUTO_OFFSET_RESET_CONFIG, "earliest")
                put(ConsumerConfig.ENABLE_AUTO_COMMIT_CONFIG, "false")
                put(ConsumerConfig.SESSION_TIMEOUT_MS_CONFIG, "30000")
            }

            val messages = mutableListOf<ChatMessageDTO>()
            KafkaConsumer<String, ChatMessageDTO>(props).use { consumer ->
                val topic = "chat-messages"

                // íŒŒí‹°ì…˜ ì •ë³´ ì¡°íšŒ í›„ ì§ì ‘ assign
                val partitionsInfo = consumer.partitionsFor(topic) ?: emptyList()
                if (partitionsInfo.isEmpty()) {
                    println("[Kafka] âš ï¸ íŒŒí‹°ì…˜ ì •ë³´ ì—†ìŒ")
                    return emptyList()
                }
                val topicPartitions = partitionsInfo.map { TopicPartition(topic, it.partition()) }
                consumer.assign(topicPartitions)

                // ì‹œì‘/ë ì˜¤í”„ì…‹ ì¡°íšŒ
                val beginningOffsets = consumer.beginningOffsets(topicPartitions)
                val endOffsets = consumer.endOffsets(topicPartitions)

                // ê° íŒŒí‹°ì…˜ì˜ ì½ê¸° ì‹œì‘ì  ê³„ì‚°: max(begin, end - limit)
                topicPartitions.forEach { tp ->
                    val begin = beginningOffsets[tp] ?: 0L
                    val end = endOffsets[tp] ?: begin
                    val start = kotlin.math.max(begin, end - limit.toLong())
                    consumer.seek(tp, start)
                    println("[Kafka] ğŸ” Partition=${tp.partition()}, begin=$begin, end=$end, start=$start")
                }

                // ì½ê¸° ë£¨í”„
                val pollTimeout = Duration.ofSeconds(2)
                val collected = mutableListOf<ChatMessageDTO>()
                var consecutiveEmpty = 0

                while (consecutiveEmpty < 3) {
                    val records = consumer.poll(pollTimeout)
                    if (records.isEmpty) {
                        consecutiveEmpty++
                    } else {
                        consecutiveEmpty = 0
                        records.forEach { record ->
                            if (record.key() == roomId && record.value() != null) {
                                collected.add(record.value())
                            }
                        }
                        // ì¶©ë¶„íˆ ëª¨ì˜€ìœ¼ë©´ ì¼ì° ì¢…ë£Œ
                        if (collected.size >= limit) break
                    }
                }

                messages.addAll(collected.takeLast(limit))
                println("[Kafka] âœ… ${messages.size}ê°œ ë©”ì‹œì§€ ë¡œë“œ ì™„ë£Œ")
            }

            messages
        } catch (e: Exception) {
            println("[Kafka] âŒ ìµœê·¼ ë©”ì‹œì§€ ë¡œë“œ ì‹¤íŒ¨: ${e.message}")
            e.printStackTrace()
            emptyList()
        }
    }

    /**
     * Kafkaì—ì„œ ë©”ì‹œì§€ ìˆ˜ì‹  â†’ ê¸€ë¡œë²Œ ë¸Œë¡œë“œìºìŠ¤íŠ¸ë¡œ ì „íŒŒ
     */
    @KafkaListener(topics = ["chat-messages"], groupId = "chat-consumer")
    fun consumeMessage(msg: ChatMessageDTO) {
        println("[Kafka] ğŸ”” Kafkaì—ì„œ ë©”ì‹œì§€ ìˆ˜ì‹ : room=${msg.roomId}, message=${msg.message}")

        val result = broadcastSink.tryEmitNext(msg)
        if (result.isFailure) {
            println("[Kafka] âš ï¸ ë¸Œë¡œë“œìºìŠ¤íŠ¸ ì‹¤íŒ¨: room=${msg.roomId}, result=$result")
        } else {
            println("[Kafka] âœ… ë¸Œë¡œë“œìºìŠ¤íŠ¸ ì„±ê³µ")
        }
    }

    /**
     * ë°© ì •ë¦¬ (ê¸€ë¡œë²Œ Sink ë°©ì‹ì—ì„œëŠ” ë³„ë„ ë¦¬ì†ŒìŠ¤ ì—†ìŒ)
     * - í•„ìš” ì‹œ noop ë˜ëŠ” í–¥í›„ roomë³„ ìì› ì‚¬ìš© ì‹œ êµ¬í˜„
     */
    fun cleanupRoom(roomId: String) {
        println("[Kafka] ğŸ§¹ ì±„íŒ…ë°© ì •ë¦¬(ê¸€ë¡œë²Œ Sink ì‚¬ìš©): room=$roomId")
        // No-op
    }
}
